{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KlymentievMaksym/IntelOb/blob/main/Lab5/Lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bc954daf",
      "metadata": {
        "id": "bc954daf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "layers = tf.keras.layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# from DE import DE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a673d41e",
      "metadata": {
        "id": "a673d41e",
        "outputId": "3c213db0-9cbc-47c3-d8a7-93124cbd20a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bb7971f6",
      "metadata": {
        "id": "bb7971f6"
      },
      "outputs": [],
      "source": [
        "filepath_save = \"./Models/Model_valAcc{val_accuracy:.2f}_valLoss{val_loss:.2f}.keras\"\n",
        "filepath_backup = \"./Backups/\"\n",
        "callbacks = [\n",
        "    # tf.keras.callbacks.ModelCheckpoint(filepath_save, monitor='val_accuracy', save_best_only=True),\n",
        "    # tf.keras.callbacks.BackupAndRestore(filepath_backup),\n",
        "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
        "]\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.RandomRotation(0.2),\n",
        "  layers.RandomContrast(0.2),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d2dc7d03",
      "metadata": {
        "id": "d2dc7d03"
      },
      "outputs": [],
      "source": [
        "def DE(pop_size, iterations, function, limits):\n",
        "    dim = len(limits)\n",
        "    limits = np.array(limits)\n",
        "    x_low = limits[:, 0]\n",
        "    x_high = limits[:, 1]\n",
        "\n",
        "    population = np.random.uniform(x_low, x_high, (pop_size, dim))\n",
        "\n",
        "    max_f = -float('inf')\n",
        "    best_f = float('inf')\n",
        "    best_pop = np.zeros(dim)\n",
        "\n",
        "    # function calls = pop_size + iterations * pop_size\n",
        "    fitness = np.array([function(X) for X in population])\n",
        "    for iteration in tqdm(\n",
        "        range(iterations),\n",
        "        desc=\"Processing\",\n",
        "        unit=\"step\",\n",
        "        bar_format=\"{l_bar}{bar:40}{r_bar}\",\n",
        "        colour='cyan',\n",
        "        total=iterations\n",
        "    ):\n",
        "        for i in range(pop_size):\n",
        "            F = np.random.uniform(1e-6, 2)\n",
        "            P = np.random.uniform(1e-6, 1)\n",
        "            r = np.random.uniform(1e-6, 1, dim)\n",
        "            x1, x2, x3 = np.random.choice(population.shape[0], size=3, replace=False)\n",
        "            while np.all(population[x1] == population[i]) or np.all(population[x2] == population[i]) or np.all(population[x3] == population[i]):\n",
        "                x1, x2, x3 = np.random.choice(population.shape[0], size=3, replace=False)\n",
        "            mutant_vector = population[x1] + F * (population[x2] - population[x3])\n",
        "            mutant_vector[r < P] = population[i][r < P]\n",
        "            mutant_fitness = function(mutant_vector)\n",
        "            if fitness[i] > mutant_fitness:\n",
        "                fitness[i] = mutant_fitness\n",
        "                population[i] = mutant_vector.copy()\n",
        "        el_min = np.argmin(fitness)\n",
        "        if best_f > fitness[el_min]:\n",
        "            best_f = fitness[el_min]\n",
        "            best_pop = population[el_min].copy()\n",
        "        el_max = np.max(fitness)\n",
        "        if max_f < el_max:\n",
        "            max_f = el_max\n",
        "\n",
        "    return best_f, best_pop\n",
        "\n",
        "def func(X):\n",
        "    # print(X)\n",
        "    amount_of_layer_1 = int(round(X[0]))\n",
        "    amount_of_layer_2 = int(round(X[1]))\n",
        "    amount_of_layer_3 = int(round(X[2]))\n",
        "    amount_of_one_dence = int(round(X[3]))\n",
        "    amount_of_one_filters = int(round(X[4]))\n",
        "    # print(np.int64(np.round(X)))\n",
        "    # print(amount_of_layer_1, amount_of_layer_2, amount_of_layer_3, amount_of_one_dence, amount_of_one_filters)\n",
        "    model_layers = [\n",
        "        layers.Input(shape=(32, 32, 3)),\n",
        "        data_augmentation\n",
        "    ]\n",
        "\n",
        "    for _ in range(amount_of_layer_1):\n",
        "        model_layers.append(layers.Conv2D(amount_of_one_filters, (3, 3), activation='relu', padding='same'))\n",
        "        model_layers.append(layers.BatchNormalization())\n",
        "    model_layers.append(layers.MaxPooling2D(2, 2))\n",
        "\n",
        "    for _ in range(amount_of_layer_2):\n",
        "        model_layers.append(layers.Conv2D(amount_of_one_filters * 2, (3, 3), activation='relu', padding='same'))\n",
        "        model_layers.append(layers.BatchNormalization())\n",
        "    model_layers.append(layers.MaxPooling2D(2, 2))\n",
        "    model_layers.append(layers.Dropout(0.3))\n",
        "\n",
        "    for _ in range(amount_of_layer_3):\n",
        "        model_layers.append(layers.Conv2D(amount_of_one_filters * 4, (3, 3), activation='relu', padding='same'))\n",
        "        model_layers.append(layers.BatchNormalization())\n",
        "    model_layers.append(layers.MaxPooling2D(4, 4))\n",
        "    model_layers.append(layers.Dropout(0.4))\n",
        "\n",
        "    model_layers.append(layers.Flatten())\n",
        "    for _ in range(amount_of_one_dence):\n",
        "        model_layers.append(layers.Dense(amount_of_one_filters * 8, activation='relu'))\n",
        "    model_layers.append(layers.Dropout(0.5))\n",
        "    model_layers.append(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model = tf.keras.models.Sequential(model_layers)\n",
        "    # model.summary()\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=2, name=\"Top2\")])\n",
        "    history = model.fit(x_train, y_train, batch_size=128, epochs=100, validation_data=(x_val, y_val), callbacks=callbacks)\n",
        "    index = np.argmax(history.history['val_loss'])\n",
        "    return (1.0 - history.history['val_accuracy'][index]) + history.history['val_loss'][index]\n",
        "\n",
        "func_limits = [[1, 4], [0, 4], [0, 4], [1, 4], [16, 128]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e21c7b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e21c7b9",
        "outputId": "26c9ae88-3b20-4d1a-ec92-b70f18028ffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - Top2: 0.4079 - accuracy: 0.2251 - loss: 2.3337 - val_Top2: 0.2178 - val_accuracy: 0.1159 - val_loss: 3.2192\n",
            "Epoch 2/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 46ms/step - Top2: 0.6096 - accuracy: 0.3807 - loss: 1.6972 - val_Top2: 0.6211 - val_accuracy: 0.3797 - val_loss: 1.8499\n",
            "Epoch 3/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - Top2: 0.6644 - accuracy: 0.4422 - loss: 1.5552 - val_Top2: 0.5193 - val_accuracy: 0.2915 - val_loss: 2.2746\n",
            "Epoch 4/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - Top2: 0.6963 - accuracy: 0.4778 - loss: 1.4544 - val_Top2: 0.6636 - val_accuracy: 0.4366 - val_loss: 1.6269\n",
            "Epoch 5/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 47ms/step - Top2: 0.7112 - accuracy: 0.5005 - loss: 1.3977 - val_Top2: 0.6111 - val_accuracy: 0.4348 - val_loss: 1.7057\n",
            "Epoch 6/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - Top2: 0.7332 - accuracy: 0.5235 - loss: 1.3360 - val_Top2: 0.6754 - val_accuracy: 0.4678 - val_loss: 1.5197\n",
            "Epoch 7/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - Top2: 0.7462 - accuracy: 0.5386 - loss: 1.2943 - val_Top2: 0.6665 - val_accuracy: 0.4810 - val_loss: 1.5073\n",
            "Epoch 8/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - Top2: 0.7528 - accuracy: 0.5464 - loss: 1.2761 - val_Top2: 0.7581 - val_accuracy: 0.5714 - val_loss: 1.2323\n",
            "Epoch 9/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - Top2: 0.7745 - accuracy: 0.5727 - loss: 1.2037 - val_Top2: 0.7382 - val_accuracy: 0.5238 - val_loss: 1.3347\n",
            "Epoch 10/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - Top2: 0.7739 - accuracy: 0.5754 - loss: 1.2072 - val_Top2: 0.6875 - val_accuracy: 0.5082 - val_loss: 1.4692\n",
            "Epoch 11/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 50ms/step - Top2: 0.7825 - accuracy: 0.5854 - loss: 1.1667 - val_Top2: 0.7302 - val_accuracy: 0.5467 - val_loss: 1.3222\n",
            "Epoch 12/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - Top2: 0.7862 - accuracy: 0.5947 - loss: 1.1512 - val_Top2: 0.7770 - val_accuracy: 0.5671 - val_loss: 1.2162\n",
            "Epoch 13/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 50ms/step - Top2: 0.7974 - accuracy: 0.6077 - loss: 1.1246 - val_Top2: 0.7407 - val_accuracy: 0.5544 - val_loss: 1.2643\n",
            "Epoch 14/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 47ms/step - Top2: 0.8006 - accuracy: 0.6164 - loss: 1.1021 - val_Top2: 0.7917 - val_accuracy: 0.5910 - val_loss: 1.1555\n",
            "Epoch 15/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - Top2: 0.8034 - accuracy: 0.6164 - loss: 1.0901 - val_Top2: 0.6243 - val_accuracy: 0.4593 - val_loss: 1.8719\n",
            "Epoch 16/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 47ms/step - Top2: 0.8082 - accuracy: 0.6290 - loss: 1.0699 - val_Top2: 0.7615 - val_accuracy: 0.5871 - val_loss: 1.1894\n",
            "Epoch 17/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 45ms/step - Top2: 0.8094 - accuracy: 0.6324 - loss: 1.0588 - val_Top2: 0.8092 - val_accuracy: 0.6371 - val_loss: 1.0707\n",
            "Epoch 18/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - Top2: 0.8151 - accuracy: 0.6318 - loss: 1.0496 - val_Top2: 0.7597 - val_accuracy: 0.5835 - val_loss: 1.2236\n",
            "Epoch 19/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - Top2: 0.8225 - accuracy: 0.6427 - loss: 1.0247 - val_Top2: 0.7843 - val_accuracy: 0.6086 - val_loss: 1.1408\n",
            "Epoch 20/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 52ms/step - Top2: 0.8204 - accuracy: 0.6361 - loss: 1.0333 - val_Top2: 0.8239 - val_accuracy: 0.6482 - val_loss: 1.0106\n",
            "Epoch 21/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - Top2: 0.8251 - accuracy: 0.6498 - loss: 1.0085 - val_Top2: 0.7710 - val_accuracy: 0.5873 - val_loss: 1.2765\n",
            "Epoch 22/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - Top2: 0.8269 - accuracy: 0.6488 - loss: 1.0049 - val_Top2: 0.8328 - val_accuracy: 0.6633 - val_loss: 0.9826\n",
            "Epoch 23/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - Top2: 0.8305 - accuracy: 0.6545 - loss: 0.9916 - val_Top2: 0.8071 - val_accuracy: 0.6357 - val_loss: 1.0667\n",
            "Epoch 24/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 45ms/step - Top2: 0.8301 - accuracy: 0.6578 - loss: 0.9895 - val_Top2: 0.8062 - val_accuracy: 0.6378 - val_loss: 1.0668\n",
            "Epoch 25/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 45ms/step - Top2: 0.8332 - accuracy: 0.6676 - loss: 0.9643 - val_Top2: 0.7452 - val_accuracy: 0.5782 - val_loss: 1.2986\n",
            "Epoch 26/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - Top2: 0.8343 - accuracy: 0.6648 - loss: 0.9667 - val_Top2: 0.8020 - val_accuracy: 0.6324 - val_loss: 1.1036\n",
            "Epoch 27/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - Top2: 0.8373 - accuracy: 0.6690 - loss: 0.9518 - val_Top2: 0.8000 - val_accuracy: 0.6109 - val_loss: 1.1434\n",
            "Epoch 1/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 139ms/step - Top2: 0.4087 - accuracy: 0.2257 - loss: 2.6634 - val_Top2: 0.2204 - val_accuracy: 0.1117 - val_loss: 3.3960\n",
            "Epoch 2/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 135ms/step - Top2: 0.6073 - accuracy: 0.3787 - loss: 1.7004 - val_Top2: 0.6346 - val_accuracy: 0.4068 - val_loss: 1.7049\n",
            "Epoch 3/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 135ms/step - Top2: 0.6720 - accuracy: 0.4418 - loss: 1.5287 - val_Top2: 0.6023 - val_accuracy: 0.4011 - val_loss: 1.7552\n",
            "Epoch 4/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 136ms/step - Top2: 0.7260 - accuracy: 0.5055 - loss: 1.3721 - val_Top2: 0.7298 - val_accuracy: 0.5225 - val_loss: 1.3931\n",
            "Epoch 5/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 134ms/step - Top2: 0.7555 - accuracy: 0.5447 - loss: 1.2786 - val_Top2: 0.6920 - val_accuracy: 0.5130 - val_loss: 1.4755\n",
            "Epoch 6/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 136ms/step - Top2: 0.7783 - accuracy: 0.5814 - loss: 1.1904 - val_Top2: 0.7393 - val_accuracy: 0.5577 - val_loss: 1.3894\n",
            "Epoch 7/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 135ms/step - Top2: 0.7961 - accuracy: 0.6041 - loss: 1.1302 - val_Top2: 0.8016 - val_accuracy: 0.6120 - val_loss: 1.1074\n",
            "Epoch 8/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 135ms/step - Top2: 0.8053 - accuracy: 0.6158 - loss: 1.0887 - val_Top2: 0.7838 - val_accuracy: 0.5899 - val_loss: 1.1828\n",
            "Epoch 9/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 133ms/step - Top2: 0.8195 - accuracy: 0.6424 - loss: 1.0210 - val_Top2: 0.8294 - val_accuracy: 0.6572 - val_loss: 0.9655\n",
            "Epoch 10/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 135ms/step - Top2: 0.8292 - accuracy: 0.6579 - loss: 0.9894 - val_Top2: 0.7792 - val_accuracy: 0.6032 - val_loss: 1.1835\n",
            "Epoch 11/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 134ms/step - Top2: 0.8404 - accuracy: 0.6774 - loss: 0.9480 - val_Top2: 0.7267 - val_accuracy: 0.5741 - val_loss: 1.4044\n",
            "Epoch 12/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 134ms/step - Top2: 0.8532 - accuracy: 0.6903 - loss: 0.9022 - val_Top2: 0.8243 - val_accuracy: 0.6589 - val_loss: 1.0060\n",
            "Epoch 13/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 134ms/step - Top2: 0.8565 - accuracy: 0.7047 - loss: 0.8692 - val_Top2: 0.8244 - val_accuracy: 0.6614 - val_loss: 1.0291\n",
            "Epoch 14/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 135ms/step - Top2: 0.8695 - accuracy: 0.7171 - loss: 0.8286 - val_Top2: 0.8264 - val_accuracy: 0.6632 - val_loss: 1.0107\n",
            "Epoch 1/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 153ms/step - Top2: 0.4541 - accuracy: 0.2488 - loss: 2.1133 - val_Top2: 0.2048 - val_accuracy: 0.0970 - val_loss: 3.2153\n",
            "Epoch 2/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 146ms/step - Top2: 0.6226 - accuracy: 0.3930 - loss: 1.6612 - val_Top2: 0.6575 - val_accuracy: 0.4188 - val_loss: 1.6154\n",
            "Epoch 3/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 147ms/step - Top2: 0.6978 - accuracy: 0.4778 - loss: 1.4480 - val_Top2: 0.6195 - val_accuracy: 0.4409 - val_loss: 1.7940\n",
            "Epoch 4/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 146ms/step - Top2: 0.7419 - accuracy: 0.5289 - loss: 1.3182 - val_Top2: 0.6454 - val_accuracy: 0.4573 - val_loss: 1.5928\n",
            "Epoch 5/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 148ms/step - Top2: 0.7705 - accuracy: 0.5747 - loss: 1.2196 - val_Top2: 0.6937 - val_accuracy: 0.4995 - val_loss: 1.5277\n",
            "Epoch 6/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 145ms/step - Top2: 0.7910 - accuracy: 0.5998 - loss: 1.1411 - val_Top2: 0.7026 - val_accuracy: 0.5191 - val_loss: 1.5789\n",
            "Epoch 7/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 148ms/step - Top2: 0.8043 - accuracy: 0.6183 - loss: 1.0881 - val_Top2: 0.7605 - val_accuracy: 0.5790 - val_loss: 1.2229\n",
            "Epoch 8/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 147ms/step - Top2: 0.8220 - accuracy: 0.6477 - loss: 1.0166 - val_Top2: 0.8083 - val_accuracy: 0.6434 - val_loss: 1.0348\n",
            "Epoch 9/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 146ms/step - Top2: 0.8332 - accuracy: 0.6606 - loss: 0.9776 - val_Top2: 0.7986 - val_accuracy: 0.6456 - val_loss: 1.0535\n",
            "Epoch 10/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 146ms/step - Top2: 0.8392 - accuracy: 0.6743 - loss: 0.9471 - val_Top2: 0.7759 - val_accuracy: 0.6261 - val_loss: 1.1641\n",
            "Epoch 11/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 147ms/step - Top2: 0.8484 - accuracy: 0.6931 - loss: 0.9016 - val_Top2: 0.8632 - val_accuracy: 0.7087 - val_loss: 0.8494\n",
            "Epoch 12/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 147ms/step - Top2: 0.8602 - accuracy: 0.7018 - loss: 0.8649 - val_Top2: 0.8551 - val_accuracy: 0.7076 - val_loss: 0.8623\n",
            "Epoch 13/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 145ms/step - Top2: 0.8660 - accuracy: 0.7203 - loss: 0.8291 - val_Top2: 0.8373 - val_accuracy: 0.6830 - val_loss: 0.9388\n",
            "Epoch 14/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 148ms/step - Top2: 0.8730 - accuracy: 0.7279 - loss: 0.7943 - val_Top2: 0.8642 - val_accuracy: 0.7070 - val_loss: 0.8515\n",
            "Epoch 15/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 146ms/step - Top2: 0.8785 - accuracy: 0.7359 - loss: 0.7769 - val_Top2: 0.8388 - val_accuracy: 0.6900 - val_loss: 0.9233\n",
            "Epoch 16/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 146ms/step - Top2: 0.8824 - accuracy: 0.7439 - loss: 0.7568 - val_Top2: 0.8602 - val_accuracy: 0.7109 - val_loss: 0.8637\n",
            "Epoch 1/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 91ms/step - Top2: 0.4345 - accuracy: 0.2442 - loss: 2.2206 - val_Top2: 0.2098 - val_accuracy: 0.1055 - val_loss: 3.4850\n",
            "Epoch 2/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 86ms/step - Top2: 0.6264 - accuracy: 0.3949 - loss: 1.6549 - val_Top2: 0.5779 - val_accuracy: 0.3732 - val_loss: 1.8021\n",
            "Epoch 3/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - Top2: 0.7019 - accuracy: 0.4770 - loss: 1.4508 - val_Top2: 0.6829 - val_accuracy: 0.4564 - val_loss: 1.5019\n",
            "Epoch 4/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - Top2: 0.7440 - accuracy: 0.5271 - loss: 1.3233 - val_Top2: 0.6470 - val_accuracy: 0.4472 - val_loss: 1.5351\n",
            "Epoch 5/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 86ms/step - Top2: 0.7640 - accuracy: 0.5577 - loss: 1.2416 - val_Top2: 0.7130 - val_accuracy: 0.5049 - val_loss: 1.4073\n",
            "Epoch 6/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - Top2: 0.7837 - accuracy: 0.5843 - loss: 1.1675 - val_Top2: 0.7386 - val_accuracy: 0.5243 - val_loss: 1.4267\n",
            "Epoch 7/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - Top2: 0.7999 - accuracy: 0.6104 - loss: 1.1135 - val_Top2: 0.7729 - val_accuracy: 0.5777 - val_loss: 1.2631\n",
            "Epoch 8/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - Top2: 0.8105 - accuracy: 0.6300 - loss: 1.0612 - val_Top2: 0.7882 - val_accuracy: 0.6223 - val_loss: 1.1133\n",
            "Epoch 9/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 86ms/step - Top2: 0.8203 - accuracy: 0.6405 - loss: 1.0375 - val_Top2: 0.8228 - val_accuracy: 0.6517 - val_loss: 1.0048\n",
            "Epoch 10/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 89ms/step - Top2: 0.8288 - accuracy: 0.6557 - loss: 0.9979 - val_Top2: 0.8123 - val_accuracy: 0.6429 - val_loss: 1.0411\n",
            "Epoch 11/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 90ms/step - Top2: 0.8394 - accuracy: 0.6685 - loss: 0.9540 - val_Top2: 0.8091 - val_accuracy: 0.6505 - val_loss: 1.0448\n",
            "Epoch 12/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 85ms/step - Top2: 0.8460 - accuracy: 0.6776 - loss: 0.9317 - val_Top2: 0.8087 - val_accuracy: 0.6515 - val_loss: 1.0261\n",
            "Epoch 13/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - Top2: 0.8559 - accuracy: 0.6944 - loss: 0.8844 - val_Top2: 0.8360 - val_accuracy: 0.6720 - val_loss: 0.9503\n",
            "Epoch 14/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - Top2: 0.8551 - accuracy: 0.6995 - loss: 0.8758 - val_Top2: 0.7747 - val_accuracy: 0.6363 - val_loss: 1.1790\n",
            "Epoch 15/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - Top2: 0.8575 - accuracy: 0.7038 - loss: 0.8689 - val_Top2: 0.8279 - val_accuracy: 0.6666 - val_loss: 1.0212\n",
            "Epoch 16/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - Top2: 0.8688 - accuracy: 0.7157 - loss: 0.8219 - val_Top2: 0.8418 - val_accuracy: 0.6847 - val_loss: 0.9296\n",
            "Epoch 17/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - Top2: 0.8702 - accuracy: 0.7248 - loss: 0.8059 - val_Top2: 0.8370 - val_accuracy: 0.6789 - val_loss: 0.9543\n",
            "Epoch 18/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - Top2: 0.8742 - accuracy: 0.7282 - loss: 0.7951 - val_Top2: 0.8692 - val_accuracy: 0.7183 - val_loss: 0.8282\n",
            "Epoch 19/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - Top2: 0.8787 - accuracy: 0.7335 - loss: 0.7740 - val_Top2: 0.8521 - val_accuracy: 0.7082 - val_loss: 0.8838\n",
            "Epoch 20/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - Top2: 0.8822 - accuracy: 0.7414 - loss: 0.7555 - val_Top2: 0.8345 - val_accuracy: 0.6866 - val_loss: 0.9592\n",
            "Epoch 21/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 90ms/step - Top2: 0.8863 - accuracy: 0.7432 - loss: 0.7527 - val_Top2: 0.8779 - val_accuracy: 0.7342 - val_loss: 0.7751\n",
            "Epoch 22/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - Top2: 0.8870 - accuracy: 0.7478 - loss: 0.7357 - val_Top2: 0.8587 - val_accuracy: 0.7129 - val_loss: 0.8711\n",
            "Epoch 23/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - Top2: 0.8920 - accuracy: 0.7564 - loss: 0.7166 - val_Top2: 0.8612 - val_accuracy: 0.6977 - val_loss: 0.9304\n",
            "Epoch 24/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - Top2: 0.8951 - accuracy: 0.7554 - loss: 0.7136 - val_Top2: 0.8697 - val_accuracy: 0.7253 - val_loss: 0.8348\n",
            "Epoch 25/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 90ms/step - Top2: 0.8993 - accuracy: 0.7609 - loss: 0.6978 - val_Top2: 0.8367 - val_accuracy: 0.6877 - val_loss: 0.9908\n",
            "Epoch 26/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 86ms/step - Top2: 0.8923 - accuracy: 0.7613 - loss: 0.6970 - val_Top2: 0.8736 - val_accuracy: 0.7361 - val_loss: 0.7859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   0%|\u001b[36m                                        \u001b[0m| 0/4 [00:00<?, ?step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - Top2: 0.4170 - accuracy: 0.2294 - loss: 2.1945 - val_Top2: 0.2185 - val_accuracy: 0.1183 - val_loss: 4.4656\n",
            "Epoch 2/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - Top2: 0.6103 - accuracy: 0.3854 - loss: 1.6863 - val_Top2: 0.6106 - val_accuracy: 0.3930 - val_loss: 1.7140\n",
            "Epoch 3/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - Top2: 0.6709 - accuracy: 0.4443 - loss: 1.5412 - val_Top2: 0.5889 - val_accuracy: 0.3739 - val_loss: 1.7077\n",
            "Epoch 4/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - Top2: 0.7067 - accuracy: 0.4901 - loss: 1.4284 - val_Top2: 0.5488 - val_accuracy: 0.3328 - val_loss: 2.1009\n",
            "Epoch 5/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - Top2: 0.7276 - accuracy: 0.5135 - loss: 1.3608 - val_Top2: 0.7083 - val_accuracy: 0.5036 - val_loss: 1.3642\n",
            "Epoch 6/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - Top2: 0.7376 - accuracy: 0.5345 - loss: 1.3209 - val_Top2: 0.6412 - val_accuracy: 0.4510 - val_loss: 1.6022\n",
            "Epoch 7/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - Top2: 0.7513 - accuracy: 0.5459 - loss: 1.2804 - val_Top2: 0.7529 - val_accuracy: 0.5564 - val_loss: 1.2499\n",
            "Epoch 8/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - Top2: 0.7608 - accuracy: 0.5634 - loss: 1.2412 - val_Top2: 0.7771 - val_accuracy: 0.5857 - val_loss: 1.1621\n",
            "Epoch 9/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - Top2: 0.7739 - accuracy: 0.5813 - loss: 1.1919 - val_Top2: 0.6984 - val_accuracy: 0.5260 - val_loss: 1.3949\n",
            "Epoch 10/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - Top2: 0.7816 - accuracy: 0.5849 - loss: 1.1689 - val_Top2: 0.7575 - val_accuracy: 0.5514 - val_loss: 1.2598\n",
            "Epoch 11/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - Top2: 0.7869 - accuracy: 0.5951 - loss: 1.1502 - val_Top2: 0.7694 - val_accuracy: 0.5688 - val_loss: 1.2305\n",
            "Epoch 12/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - Top2: 0.7879 - accuracy: 0.5961 - loss: 1.1483 - val_Top2: 0.7765 - val_accuracy: 0.5864 - val_loss: 1.1775\n",
            "Epoch 13/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - Top2: 0.7950 - accuracy: 0.6085 - loss: 1.1127 - val_Top2: 0.7872 - val_accuracy: 0.5927 - val_loss: 1.1433\n",
            "Epoch 14/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - Top2: 0.8032 - accuracy: 0.6156 - loss: 1.0946 - val_Top2: 0.7399 - val_accuracy: 0.5508 - val_loss: 1.3059\n",
            "Epoch 15/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - Top2: 0.8033 - accuracy: 0.6243 - loss: 1.0794 - val_Top2: 0.8071 - val_accuracy: 0.6311 - val_loss: 1.0700\n",
            "Epoch 16/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - Top2: 0.8096 - accuracy: 0.6348 - loss: 1.0540 - val_Top2: 0.8082 - val_accuracy: 0.6338 - val_loss: 1.0520\n",
            "Epoch 17/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - Top2: 0.8164 - accuracy: 0.6371 - loss: 1.0430 - val_Top2: 0.7669 - val_accuracy: 0.5812 - val_loss: 1.2278\n",
            "Epoch 18/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - Top2: 0.8202 - accuracy: 0.6424 - loss: 1.0247 - val_Top2: 0.6716 - val_accuracy: 0.4933 - val_loss: 1.6310\n",
            "Epoch 19/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - Top2: 0.8265 - accuracy: 0.6478 - loss: 1.0125 - val_Top2: 0.8071 - val_accuracy: 0.6197 - val_loss: 1.1068\n",
            "Epoch 20/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - Top2: 0.8260 - accuracy: 0.6528 - loss: 1.0017 - val_Top2: 0.7688 - val_accuracy: 0.5801 - val_loss: 1.2478\n",
            "Epoch 21/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - Top2: 0.8220 - accuracy: 0.6534 - loss: 1.0078 - val_Top2: 0.8182 - val_accuracy: 0.6496 - val_loss: 1.0257\n",
            "Epoch 22/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - Top2: 0.8311 - accuracy: 0.6547 - loss: 0.9892 - val_Top2: 0.8210 - val_accuracy: 0.6536 - val_loss: 1.0322\n",
            "Epoch 23/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - Top2: 0.8332 - accuracy: 0.6678 - loss: 0.9624 - val_Top2: 0.8434 - val_accuracy: 0.6824 - val_loss: 0.9356\n",
            "Epoch 24/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - Top2: 0.8328 - accuracy: 0.6647 - loss: 0.9630 - val_Top2: 0.8042 - val_accuracy: 0.6287 - val_loss: 1.0839\n",
            "Epoch 25/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - Top2: 0.8379 - accuracy: 0.6678 - loss: 0.9550 - val_Top2: 0.8039 - val_accuracy: 0.6504 - val_loss: 1.0429\n",
            "Epoch 26/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - Top2: 0.8374 - accuracy: 0.6730 - loss: 0.9405 - val_Top2: 0.7705 - val_accuracy: 0.5993 - val_loss: 1.1866\n",
            "Epoch 27/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - Top2: 0.8426 - accuracy: 0.6733 - loss: 0.9361 - val_Top2: 0.8092 - val_accuracy: 0.6494 - val_loss: 1.0511\n",
            "Epoch 28/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - Top2: 0.8462 - accuracy: 0.6827 - loss: 0.9066 - val_Top2: 0.7647 - val_accuracy: 0.5965 - val_loss: 1.2079\n",
            "Epoch 1/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 117ms/step - Top2: 0.4339 - accuracy: 0.2417 - loss: 2.2574 - val_Top2: 0.2866 - val_accuracy: 0.1381 - val_loss: 3.1309\n",
            "Epoch 2/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 111ms/step - Top2: 0.6101 - accuracy: 0.3752 - loss: 1.7032 - val_Top2: 0.4866 - val_accuracy: 0.3071 - val_loss: 2.2356\n",
            "Epoch 3/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 114ms/step - Top2: 0.6753 - accuracy: 0.4479 - loss: 1.5239 - val_Top2: 0.5353 - val_accuracy: 0.3272 - val_loss: 2.0364\n",
            "Epoch 4/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 114ms/step - Top2: 0.7135 - accuracy: 0.4993 - loss: 1.4030 - val_Top2: 0.6934 - val_accuracy: 0.4853 - val_loss: 1.4970\n",
            "Epoch 5/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 111ms/step - Top2: 0.7437 - accuracy: 0.5336 - loss: 1.3129 - val_Top2: 0.7492 - val_accuracy: 0.5312 - val_loss: 1.3537\n",
            "Epoch 6/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 111ms/step - Top2: 0.7660 - accuracy: 0.5661 - loss: 1.2347 - val_Top2: 0.7325 - val_accuracy: 0.5298 - val_loss: 1.4054\n",
            "Epoch 7/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 111ms/step - Top2: 0.7842 - accuracy: 0.5855 - loss: 1.1732 - val_Top2: 0.7221 - val_accuracy: 0.5158 - val_loss: 1.3739\n",
            "Epoch 8/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 111ms/step - Top2: 0.7988 - accuracy: 0.6077 - loss: 1.1252 - val_Top2: 0.7320 - val_accuracy: 0.5342 - val_loss: 1.3953\n",
            "Epoch 9/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 113ms/step - Top2: 0.8061 - accuracy: 0.6230 - loss: 1.0784 - val_Top2: 0.7522 - val_accuracy: 0.5545 - val_loss: 1.3060\n",
            "Epoch 10/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 114ms/step - Top2: 0.8204 - accuracy: 0.6395 - loss: 1.0317 - val_Top2: 0.7988 - val_accuracy: 0.6156 - val_loss: 1.1444\n",
            "Epoch 11/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 110ms/step - Top2: 0.8224 - accuracy: 0.6542 - loss: 1.0001 - val_Top2: 0.8215 - val_accuracy: 0.6537 - val_loss: 1.0259\n",
            "Epoch 12/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 111ms/step - Top2: 0.8347 - accuracy: 0.6700 - loss: 0.9638 - val_Top2: 0.8248 - val_accuracy: 0.6700 - val_loss: 0.9759\n",
            "Epoch 13/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 114ms/step - Top2: 0.8426 - accuracy: 0.6821 - loss: 0.9232 - val_Top2: 0.8226 - val_accuracy: 0.6702 - val_loss: 0.9726\n",
            "Epoch 14/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 113ms/step - Top2: 0.8517 - accuracy: 0.6936 - loss: 0.9037 - val_Top2: 0.8112 - val_accuracy: 0.6435 - val_loss: 1.0481\n",
            "Epoch 15/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - Top2: 0.8540 - accuracy: 0.6928 - loss: 0.8884 - val_Top2: 0.8384 - val_accuracy: 0.6944 - val_loss: 0.9123\n",
            "Epoch 16/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 111ms/step - Top2: 0.8579 - accuracy: 0.7066 - loss: 0.8592 - val_Top2: 0.8372 - val_accuracy: 0.6802 - val_loss: 0.9449\n",
            "Epoch 17/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 111ms/step - Top2: 0.8638 - accuracy: 0.7154 - loss: 0.8432 - val_Top2: 0.8445 - val_accuracy: 0.6869 - val_loss: 0.9359\n",
            "Epoch 18/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 114ms/step - Top2: 0.8689 - accuracy: 0.7268 - loss: 0.8155 - val_Top2: 0.7962 - val_accuracy: 0.6392 - val_loss: 1.1112\n",
            "Epoch 19/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 110ms/step - Top2: 0.8749 - accuracy: 0.7327 - loss: 0.7940 - val_Top2: 0.8560 - val_accuracy: 0.7022 - val_loss: 0.8888\n",
            "Epoch 20/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 111ms/step - Top2: 0.8812 - accuracy: 0.7415 - loss: 0.7621 - val_Top2: 0.8593 - val_accuracy: 0.7204 - val_loss: 0.8399\n",
            "Epoch 21/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - Top2: 0.8819 - accuracy: 0.7421 - loss: 0.7599 - val_Top2: 0.8716 - val_accuracy: 0.7257 - val_loss: 0.8031\n",
            "Epoch 22/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 111ms/step - Top2: 0.8861 - accuracy: 0.7503 - loss: 0.7365 - val_Top2: 0.8693 - val_accuracy: 0.7355 - val_loss: 0.8045\n",
            "Epoch 23/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - Top2: 0.8921 - accuracy: 0.7559 - loss: 0.7177 - val_Top2: 0.8243 - val_accuracy: 0.6479 - val_loss: 1.1056\n",
            "Epoch 24/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 114ms/step - Top2: 0.8937 - accuracy: 0.7634 - loss: 0.7042 - val_Top2: 0.8530 - val_accuracy: 0.7193 - val_loss: 0.8479\n",
            "Epoch 25/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 114ms/step - Top2: 0.8969 - accuracy: 0.7682 - loss: 0.6838 - val_Top2: 0.8637 - val_accuracy: 0.7324 - val_loss: 0.8486\n",
            "Epoch 26/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 113ms/step - Top2: 0.9003 - accuracy: 0.7739 - loss: 0.6697 - val_Top2: 0.8936 - val_accuracy: 0.7612 - val_loss: 0.7186\n",
            "Epoch 27/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - Top2: 0.9056 - accuracy: 0.7781 - loss: 0.6553 - val_Top2: 0.8851 - val_accuracy: 0.7600 - val_loss: 0.7380\n",
            "Epoch 28/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 111ms/step - Top2: 0.9092 - accuracy: 0.7823 - loss: 0.6390 - val_Top2: 0.8724 - val_accuracy: 0.7406 - val_loss: 0.8018\n",
            "Epoch 29/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 110ms/step - Top2: 0.9082 - accuracy: 0.7832 - loss: 0.6379 - val_Top2: 0.8586 - val_accuracy: 0.7164 - val_loss: 0.9045\n",
            "Epoch 30/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - Top2: 0.9111 - accuracy: 0.7890 - loss: 0.6299 - val_Top2: 0.8495 - val_accuracy: 0.7092 - val_loss: 0.9237\n",
            "Epoch 31/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 111ms/step - Top2: 0.9126 - accuracy: 0.7955 - loss: 0.6056 - val_Top2: 0.8847 - val_accuracy: 0.7553 - val_loss: 0.7500\n",
            "Epoch 1/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 81ms/step - Top2: 0.4428 - accuracy: 0.2513 - loss: 2.2497 - val_Top2: 0.2184 - val_accuracy: 0.0959 - val_loss: 3.9669\n",
            "Epoch 2/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 79ms/step - Top2: 0.6296 - accuracy: 0.4023 - loss: 1.6436 - val_Top2: 0.5913 - val_accuracy: 0.3991 - val_loss: 1.7039\n",
            "Epoch 3/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 78ms/step - Top2: 0.7047 - accuracy: 0.4753 - loss: 1.4432 - val_Top2: 0.6820 - val_accuracy: 0.4729 - val_loss: 1.4686\n",
            "Epoch 4/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 78ms/step - Top2: 0.7400 - accuracy: 0.5303 - loss: 1.3169 - val_Top2: 0.7029 - val_accuracy: 0.5002 - val_loss: 1.4607\n",
            "Epoch 5/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - Top2: 0.7602 - accuracy: 0.5592 - loss: 1.2369 - val_Top2: 0.6716 - val_accuracy: 0.4870 - val_loss: 1.4773\n",
            "Epoch 6/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 79ms/step - Top2: 0.7831 - accuracy: 0.5821 - loss: 1.1769 - val_Top2: 0.7518 - val_accuracy: 0.5575 - val_loss: 1.2468\n",
            "Epoch 7/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - Top2: 0.7968 - accuracy: 0.6024 - loss: 1.1243 - val_Top2: 0.7717 - val_accuracy: 0.5695 - val_loss: 1.2487\n",
            "Epoch 8/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 79ms/step - Top2: 0.8049 - accuracy: 0.6132 - loss: 1.0935 - val_Top2: 0.7716 - val_accuracy: 0.5900 - val_loss: 1.1484\n",
            "Epoch 9/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - Top2: 0.8161 - accuracy: 0.6346 - loss: 1.0481 - val_Top2: 0.7590 - val_accuracy: 0.5965 - val_loss: 1.1781\n",
            "Epoch 10/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 79ms/step - Top2: 0.8231 - accuracy: 0.6464 - loss: 1.0199 - val_Top2: 0.7945 - val_accuracy: 0.6224 - val_loss: 1.1030\n",
            "Epoch 11/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 78ms/step - Top2: 0.8283 - accuracy: 0.6528 - loss: 0.9863 - val_Top2: 0.7906 - val_accuracy: 0.6177 - val_loss: 1.1427\n",
            "Epoch 12/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - Top2: 0.8368 - accuracy: 0.6672 - loss: 0.9536 - val_Top2: 0.8193 - val_accuracy: 0.6487 - val_loss: 1.0489\n",
            "Epoch 13/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 79ms/step - Top2: 0.8412 - accuracy: 0.6717 - loss: 0.9439 - val_Top2: 0.8100 - val_accuracy: 0.6400 - val_loss: 1.0446\n",
            "Epoch 14/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - Top2: 0.8512 - accuracy: 0.6889 - loss: 0.8993 - val_Top2: 0.8533 - val_accuracy: 0.6960 - val_loss: 0.8608\n",
            "Epoch 15/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - Top2: 0.8524 - accuracy: 0.6912 - loss: 0.8954 - val_Top2: 0.8029 - val_accuracy: 0.6294 - val_loss: 1.0993\n",
            "Epoch 16/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - Top2: 0.8593 - accuracy: 0.6975 - loss: 0.8707 - val_Top2: 0.8567 - val_accuracy: 0.7014 - val_loss: 0.8666\n",
            "Epoch 17/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 79ms/step - Top2: 0.8636 - accuracy: 0.7045 - loss: 0.8509 - val_Top2: 0.8589 - val_accuracy: 0.7123 - val_loss: 0.8475\n",
            "Epoch 18/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 79ms/step - Top2: 0.8630 - accuracy: 0.7099 - loss: 0.8348 - val_Top2: 0.8443 - val_accuracy: 0.6847 - val_loss: 0.9004\n",
            "Epoch 19/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 78ms/step - Top2: 0.8702 - accuracy: 0.7142 - loss: 0.8173 - val_Top2: 0.8141 - val_accuracy: 0.6653 - val_loss: 1.0084\n",
            "Epoch 20/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - Top2: 0.8706 - accuracy: 0.7166 - loss: 0.8142 - val_Top2: 0.8628 - val_accuracy: 0.7175 - val_loss: 0.8344\n",
            "Epoch 21/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 79ms/step - Top2: 0.8750 - accuracy: 0.7248 - loss: 0.7985 - val_Top2: 0.8576 - val_accuracy: 0.7016 - val_loss: 0.8777\n",
            "Epoch 22/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - Top2: 0.8756 - accuracy: 0.7305 - loss: 0.7861 - val_Top2: 0.8324 - val_accuracy: 0.6802 - val_loss: 0.9586\n",
            "Epoch 23/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 79ms/step - Top2: 0.8762 - accuracy: 0.7303 - loss: 0.7847 - val_Top2: 0.8555 - val_accuracy: 0.6962 - val_loss: 0.9377\n",
            "Epoch 24/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 78ms/step - Top2: 0.8764 - accuracy: 0.7323 - loss: 0.7812 - val_Top2: 0.7918 - val_accuracy: 0.6405 - val_loss: 1.1674\n",
            "Epoch 25/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 79ms/step - Top2: 0.8853 - accuracy: 0.7398 - loss: 0.7530 - val_Top2: 0.8390 - val_accuracy: 0.6949 - val_loss: 0.9422\n",
            "Epoch 1/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - Top2: 0.4236 - accuracy: 0.2340 - loss: 2.2734 - val_Top2: 0.2045 - val_accuracy: 0.1045 - val_loss: 4.3923\n",
            "Epoch 2/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 46ms/step - Top2: 0.6080 - accuracy: 0.3910 - loss: 1.6881 - val_Top2: 0.5476 - val_accuracy: 0.3369 - val_loss: 1.9099\n",
            "Epoch 3/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - Top2: 0.6616 - accuracy: 0.4473 - loss: 1.5466 - val_Top2: 0.5116 - val_accuracy: 0.3291 - val_loss: 2.3172\n",
            "Epoch 4/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 44ms/step - Top2: 0.6952 - accuracy: 0.4746 - loss: 1.4682 - val_Top2: 0.5893 - val_accuracy: 0.3996 - val_loss: 1.7652\n",
            "Epoch 5/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - Top2: 0.7137 - accuracy: 0.5020 - loss: 1.3990 - val_Top2: 0.6204 - val_accuracy: 0.4350 - val_loss: 1.7681\n",
            "Epoch 6/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - Top2: 0.7297 - accuracy: 0.5188 - loss: 1.3434 - val_Top2: 0.7049 - val_accuracy: 0.4861 - val_loss: 1.4232\n",
            "Epoch 7/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - Top2: 0.7425 - accuracy: 0.5338 - loss: 1.3094 - val_Top2: 0.7490 - val_accuracy: 0.5344 - val_loss: 1.3164\n",
            "Epoch 8/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - Top2: 0.7607 - accuracy: 0.5598 - loss: 1.2505 - val_Top2: 0.7556 - val_accuracy: 0.5609 - val_loss: 1.2420\n",
            "Epoch 9/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 44ms/step - Top2: 0.7666 - accuracy: 0.5673 - loss: 1.2229 - val_Top2: 0.7132 - val_accuracy: 0.5321 - val_loss: 1.3861\n",
            "Epoch 10/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 44ms/step - Top2: 0.7786 - accuracy: 0.5784 - loss: 1.1900 - val_Top2: 0.7675 - val_accuracy: 0.5758 - val_loss: 1.2217\n",
            "Epoch 11/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - Top2: 0.7820 - accuracy: 0.5909 - loss: 1.1757 - val_Top2: 0.7857 - val_accuracy: 0.5908 - val_loss: 1.1713\n",
            "Epoch 12/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 44ms/step - Top2: 0.7895 - accuracy: 0.5953 - loss: 1.1473 - val_Top2: 0.7442 - val_accuracy: 0.5397 - val_loss: 1.3478\n",
            "Epoch 13/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 44ms/step - Top2: 0.7906 - accuracy: 0.6005 - loss: 1.1453 - val_Top2: 0.7532 - val_accuracy: 0.5681 - val_loss: 1.2485\n",
            "Epoch 14/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 44ms/step - Top2: 0.7966 - accuracy: 0.6116 - loss: 1.1150 - val_Top2: 0.6978 - val_accuracy: 0.4958 - val_loss: 1.4390\n",
            "Epoch 15/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - Top2: 0.8001 - accuracy: 0.6200 - loss: 1.0956 - val_Top2: 0.7955 - val_accuracy: 0.6025 - val_loss: 1.1154\n",
            "Epoch 16/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - Top2: 0.8035 - accuracy: 0.6187 - loss: 1.0908 - val_Top2: 0.7218 - val_accuracy: 0.5359 - val_loss: 1.3635\n",
            "Epoch 17/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 44ms/step - Top2: 0.8114 - accuracy: 0.6314 - loss: 1.0552 - val_Top2: 0.8182 - val_accuracy: 0.6460 - val_loss: 1.0219\n",
            "Epoch 18/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 44ms/step - Top2: 0.8148 - accuracy: 0.6364 - loss: 1.0515 - val_Top2: 0.7622 - val_accuracy: 0.5633 - val_loss: 1.3387\n",
            "Epoch 19/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - Top2: 0.8203 - accuracy: 0.6472 - loss: 1.0201 - val_Top2: 0.8138 - val_accuracy: 0.6346 - val_loss: 1.0557\n",
            "Epoch 20/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - Top2: 0.8208 - accuracy: 0.6450 - loss: 1.0265 - val_Top2: 0.8132 - val_accuracy: 0.6350 - val_loss: 1.0845\n",
            "Epoch 21/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 44ms/step - Top2: 0.8217 - accuracy: 0.6472 - loss: 1.0204 - val_Top2: 0.8012 - val_accuracy: 0.6168 - val_loss: 1.1105\n",
            "Epoch 22/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - Top2: 0.8240 - accuracy: 0.6497 - loss: 1.0063 - val_Top2: 0.7510 - val_accuracy: 0.5807 - val_loss: 1.2479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:  25%|\u001b[36m██████████                              \u001b[0m| 1/4 [50:33<2:31:39, 3033.25s/step]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 113ms/step - Top2: 0.3110 - accuracy: 0.1614 - loss: 3.2834 - val_Top2: 0.2495 - val_accuracy: 0.1232 - val_loss: 2.4207\n",
            "Epoch 2/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 108ms/step - Top2: 0.4821 - accuracy: 0.2597 - loss: 1.9563 - val_Top2: 0.5499 - val_accuracy: 0.3063 - val_loss: 1.8518\n",
            "Epoch 3/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 108ms/step - Top2: 0.5445 - accuracy: 0.3007 - loss: 1.8417 - val_Top2: 0.5115 - val_accuracy: 0.2823 - val_loss: 2.2281\n",
            "Epoch 4/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 105ms/step - Top2: 0.5826 - accuracy: 0.3452 - loss: 1.7644 - val_Top2: 0.5724 - val_accuracy: 0.3486 - val_loss: 1.7955\n",
            "Epoch 5/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 108ms/step - Top2: 0.6194 - accuracy: 0.3839 - loss: 1.6743 - val_Top2: 0.6446 - val_accuracy: 0.3971 - val_loss: 1.6788\n",
            "Epoch 6/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 108ms/step - Top2: 0.6598 - accuracy: 0.4246 - loss: 1.5848 - val_Top2: 0.5777 - val_accuracy: 0.3676 - val_loss: 1.9447\n",
            "Epoch 7/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 104ms/step - Top2: 0.6846 - accuracy: 0.4485 - loss: 1.5218 - val_Top2: 0.6048 - val_accuracy: 0.4098 - val_loss: 1.7958\n",
            "Epoch 8/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 105ms/step - Top2: 0.7079 - accuracy: 0.4808 - loss: 1.4449 - val_Top2: 0.6758 - val_accuracy: 0.4694 - val_loss: 1.5540\n",
            "Epoch 9/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 109ms/step - Top2: 0.7302 - accuracy: 0.5085 - loss: 1.3808 - val_Top2: 0.7045 - val_accuracy: 0.5081 - val_loss: 1.4743\n",
            "Epoch 10/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 105ms/step - Top2: 0.7432 - accuracy: 0.5298 - loss: 1.3316 - val_Top2: 0.6881 - val_accuracy: 0.4873 - val_loss: 1.5180\n",
            "Epoch 11/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 105ms/step - Top2: 0.7585 - accuracy: 0.5450 - loss: 1.2940 - val_Top2: 0.7236 - val_accuracy: 0.5209 - val_loss: 1.4050\n",
            "Epoch 12/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 105ms/step - Top2: 0.7659 - accuracy: 0.5600 - loss: 1.2510 - val_Top2: 0.7117 - val_accuracy: 0.5037 - val_loss: 1.5723\n",
            "Epoch 13/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 108ms/step - Top2: 0.7748 - accuracy: 0.5776 - loss: 1.2105 - val_Top2: 0.7856 - val_accuracy: 0.5971 - val_loss: 1.2088\n",
            "Epoch 14/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 108ms/step - Top2: 0.7857 - accuracy: 0.5920 - loss: 1.1781 - val_Top2: 0.7371 - val_accuracy: 0.5360 - val_loss: 1.4460\n",
            "Epoch 15/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 105ms/step - Top2: 0.7961 - accuracy: 0.6042 - loss: 1.1385 - val_Top2: 0.7170 - val_accuracy: 0.5645 - val_loss: 1.4685\n",
            "Epoch 16/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 108ms/step - Top2: 0.7950 - accuracy: 0.6122 - loss: 1.1206 - val_Top2: 0.7907 - val_accuracy: 0.5955 - val_loss: 1.2388\n",
            "Epoch 17/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 108ms/step - Top2: 0.8145 - accuracy: 0.6285 - loss: 1.0809 - val_Top2: 0.7980 - val_accuracy: 0.6136 - val_loss: 1.1918\n",
            "Epoch 18/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 105ms/step - Top2: 0.8159 - accuracy: 0.6366 - loss: 1.0551 - val_Top2: 0.7420 - val_accuracy: 0.5394 - val_loss: 1.4499\n",
            "Epoch 19/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 108ms/step - Top2: 0.8270 - accuracy: 0.6539 - loss: 1.0104 - val_Top2: 0.7881 - val_accuracy: 0.6116 - val_loss: 1.2708\n",
            "Epoch 20/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 108ms/step - Top2: 0.8268 - accuracy: 0.6535 - loss: 1.0055 - val_Top2: 0.7740 - val_accuracy: 0.5876 - val_loss: 1.3790\n",
            "Epoch 21/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 105ms/step - Top2: 0.8339 - accuracy: 0.6637 - loss: 0.9796 - val_Top2: 0.8149 - val_accuracy: 0.6392 - val_loss: 1.1278\n",
            "Epoch 22/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 105ms/step - Top2: 0.8386 - accuracy: 0.6753 - loss: 0.9629 - val_Top2: 0.8299 - val_accuracy: 0.6756 - val_loss: 1.0526\n",
            "Epoch 23/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 108ms/step - Top2: 0.8444 - accuracy: 0.6808 - loss: 0.9370 - val_Top2: 0.8470 - val_accuracy: 0.6851 - val_loss: 1.0817\n",
            "Epoch 24/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 105ms/step - Top2: 0.8485 - accuracy: 0.6869 - loss: 0.9280 - val_Top2: 0.8097 - val_accuracy: 0.6406 - val_loss: 1.3561\n",
            "Epoch 25/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 108ms/step - Top2: 0.8537 - accuracy: 0.6938 - loss: 0.8971 - val_Top2: 0.8504 - val_accuracy: 0.6937 - val_loss: 1.0607\n",
            "Epoch 26/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 105ms/step - Top2: 0.8570 - accuracy: 0.7004 - loss: 0.8798 - val_Top2: 0.8112 - val_accuracy: 0.6454 - val_loss: 1.2553\n",
            "Epoch 27/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 105ms/step - Top2: 0.8580 - accuracy: 0.7061 - loss: 0.8696 - val_Top2: 0.8375 - val_accuracy: 0.6391 - val_loss: 1.2922\n",
            "Epoch 1/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 114ms/step - Top2: 0.4367 - accuracy: 0.2431 - loss: 2.2885 - val_Top2: 0.2392 - val_accuracy: 0.1331 - val_loss: 5.0070\n",
            "Epoch 2/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 111ms/step - Top2: 0.6090 - accuracy: 0.3748 - loss: 1.6952 - val_Top2: 0.5072 - val_accuracy: 0.3029 - val_loss: 2.0210\n",
            "Epoch 3/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 111ms/step - Top2: 0.6769 - accuracy: 0.4524 - loss: 1.5136 - val_Top2: 0.7153 - val_accuracy: 0.5057 - val_loss: 1.4055\n",
            "Epoch 4/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 114ms/step - Top2: 0.7244 - accuracy: 0.5082 - loss: 1.3776 - val_Top2: 0.6961 - val_accuracy: 0.4767 - val_loss: 1.5052\n",
            "Epoch 5/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 111ms/step - Top2: 0.7491 - accuracy: 0.5382 - loss: 1.3016 - val_Top2: 0.7065 - val_accuracy: 0.4953 - val_loss: 1.4174\n",
            "Epoch 6/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 111ms/step - Top2: 0.7670 - accuracy: 0.5659 - loss: 1.2311 - val_Top2: 0.7643 - val_accuracy: 0.5799 - val_loss: 1.2174\n",
            "Epoch 7/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 111ms/step - Top2: 0.7820 - accuracy: 0.5875 - loss: 1.1750 - val_Top2: 0.7693 - val_accuracy: 0.5833 - val_loss: 1.2483\n",
            "Epoch 8/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 111ms/step - Top2: 0.7932 - accuracy: 0.5993 - loss: 1.1350 - val_Top2: 0.7727 - val_accuracy: 0.5828 - val_loss: 1.2385\n",
            "Epoch 9/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 111ms/step - Top2: 0.8052 - accuracy: 0.6266 - loss: 1.0814 - val_Top2: 0.7268 - val_accuracy: 0.5634 - val_loss: 1.3021\n",
            "Epoch 10/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 114ms/step - Top2: 0.8172 - accuracy: 0.6418 - loss: 1.0344 - val_Top2: 0.8149 - val_accuracy: 0.6474 - val_loss: 1.0241\n",
            "Epoch 11/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 114ms/step - Top2: 0.8268 - accuracy: 0.6555 - loss: 0.9997 - val_Top2: 0.8145 - val_accuracy: 0.6480 - val_loss: 1.0338\n",
            "Epoch 12/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 111ms/step - Top2: 0.8295 - accuracy: 0.6615 - loss: 0.9748 - val_Top2: 0.7946 - val_accuracy: 0.6126 - val_loss: 1.1818\n",
            "Epoch 13/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 114ms/step - Top2: 0.8407 - accuracy: 0.6834 - loss: 0.9295 - val_Top2: 0.8372 - val_accuracy: 0.6839 - val_loss: 0.9247\n",
            "Epoch 14/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 114ms/step - Top2: 0.8514 - accuracy: 0.6907 - loss: 0.9052 - val_Top2: 0.8179 - val_accuracy: 0.6624 - val_loss: 1.0050\n",
            "Epoch 15/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 111ms/step - Top2: 0.8562 - accuracy: 0.7013 - loss: 0.8717 - val_Top2: 0.8253 - val_accuracy: 0.6646 - val_loss: 0.9758\n",
            "Epoch 16/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 114ms/step - Top2: 0.8591 - accuracy: 0.7111 - loss: 0.8486 - val_Top2: 0.7742 - val_accuracy: 0.6164 - val_loss: 1.1857\n",
            "Epoch 17/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 111ms/step - Top2: 0.8665 - accuracy: 0.7164 - loss: 0.8275 - val_Top2: 0.8179 - val_accuracy: 0.6683 - val_loss: 0.9888\n",
            "Epoch 18/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 111ms/step - Top2: 0.8762 - accuracy: 0.7313 - loss: 0.7945 - val_Top2: 0.8466 - val_accuracy: 0.6897 - val_loss: 0.9533\n",
            "Epoch 1/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 152ms/step - Top2: 0.4255 - accuracy: 0.2284 - loss: 2.1939 - val_Top2: 0.2889 - val_accuracy: 0.1436 - val_loss: 2.4905\n",
            "Epoch 2/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 149ms/step - Top2: 0.6089 - accuracy: 0.3755 - loss: 1.6924 - val_Top2: 0.5979 - val_accuracy: 0.3936 - val_loss: 1.7969\n",
            "Epoch 3/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - Top2: 0.6961 - accuracy: 0.4656 - loss: 1.4724 - val_Top2: 0.5928 - val_accuracy: 0.3965 - val_loss: 2.0306\n",
            "Epoch 4/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 149ms/step - Top2: 0.7424 - accuracy: 0.5302 - loss: 1.3152 - val_Top2: 0.7190 - val_accuracy: 0.5295 - val_loss: 1.3928\n",
            "Epoch 5/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - Top2: 0.7739 - accuracy: 0.5637 - loss: 1.2147 - val_Top2: 0.7229 - val_accuracy: 0.5382 - val_loss: 1.3533\n",
            "Epoch 6/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 149ms/step - Top2: 0.7903 - accuracy: 0.5960 - loss: 1.1452 - val_Top2: 0.7177 - val_accuracy: 0.5540 - val_loss: 1.3738\n",
            "Epoch 7/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - Top2: 0.8048 - accuracy: 0.6207 - loss: 1.0874 - val_Top2: 0.8135 - val_accuracy: 0.6324 - val_loss: 1.0364\n",
            "Epoch 8/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - Top2: 0.8200 - accuracy: 0.6399 - loss: 1.0252 - val_Top2: 0.7494 - val_accuracy: 0.5749 - val_loss: 1.2455\n",
            "Epoch 9/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 147ms/step - Top2: 0.8335 - accuracy: 0.6597 - loss: 0.9816 - val_Top2: 0.7841 - val_accuracy: 0.5933 - val_loss: 1.1852\n",
            "Epoch 10/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - Top2: 0.8438 - accuracy: 0.6779 - loss: 0.9310 - val_Top2: 0.8035 - val_accuracy: 0.6283 - val_loss: 1.0931\n",
            "Epoch 11/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - Top2: 0.8535 - accuracy: 0.6902 - loss: 0.8904 - val_Top2: 0.8234 - val_accuracy: 0.6627 - val_loss: 0.9806\n",
            "Epoch 12/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - Top2: 0.8597 - accuracy: 0.7053 - loss: 0.8584 - val_Top2: 0.8005 - val_accuracy: 0.6487 - val_loss: 1.0843\n",
            "Epoch 13/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - Top2: 0.8680 - accuracy: 0.7151 - loss: 0.8284 - val_Top2: 0.8200 - val_accuracy: 0.6769 - val_loss: 0.9701\n",
            "Epoch 14/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 146ms/step - Top2: 0.8753 - accuracy: 0.7295 - loss: 0.7903 - val_Top2: 0.8650 - val_accuracy: 0.7243 - val_loss: 0.8375\n",
            "Epoch 15/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 149ms/step - Top2: 0.8767 - accuracy: 0.7377 - loss: 0.7738 - val_Top2: 0.8754 - val_accuracy: 0.7341 - val_loss: 0.7945\n",
            "Epoch 16/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - Top2: 0.8874 - accuracy: 0.7518 - loss: 0.7319 - val_Top2: 0.8545 - val_accuracy: 0.7054 - val_loss: 0.8745\n",
            "Epoch 17/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - Top2: 0.8891 - accuracy: 0.7515 - loss: 0.7217 - val_Top2: 0.8575 - val_accuracy: 0.7010 - val_loss: 0.8965\n",
            "Epoch 18/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 146ms/step - Top2: 0.8978 - accuracy: 0.7627 - loss: 0.6909 - val_Top2: 0.8867 - val_accuracy: 0.7578 - val_loss: 0.7138\n",
            "Epoch 19/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 149ms/step - Top2: 0.8995 - accuracy: 0.7714 - loss: 0.6802 - val_Top2: 0.8831 - val_accuracy: 0.7518 - val_loss: 0.7401\n",
            "Epoch 20/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 147ms/step - Top2: 0.9009 - accuracy: 0.7722 - loss: 0.6665 - val_Top2: 0.8932 - val_accuracy: 0.7610 - val_loss: 0.6904\n",
            "Epoch 21/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 147ms/step - Top2: 0.9064 - accuracy: 0.7850 - loss: 0.6348 - val_Top2: 0.8917 - val_accuracy: 0.7736 - val_loss: 0.6909\n",
            "Epoch 22/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 147ms/step - Top2: 0.9084 - accuracy: 0.7880 - loss: 0.6241 - val_Top2: 0.8985 - val_accuracy: 0.7729 - val_loss: 0.6929\n",
            "Epoch 23/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - Top2: 0.9147 - accuracy: 0.7991 - loss: 0.6011 - val_Top2: 0.9011 - val_accuracy: 0.7794 - val_loss: 0.6554\n",
            "Epoch 24/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - Top2: 0.9155 - accuracy: 0.8000 - loss: 0.5995 - val_Top2: 0.8803 - val_accuracy: 0.7492 - val_loss: 0.7968\n",
            "Epoch 25/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 147ms/step - Top2: 0.9163 - accuracy: 0.8022 - loss: 0.5901 - val_Top2: 0.8840 - val_accuracy: 0.7700 - val_loss: 0.7172\n",
            "Epoch 26/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - Top2: 0.9221 - accuracy: 0.8056 - loss: 0.5668 - val_Top2: 0.9076 - val_accuracy: 0.7822 - val_loss: 0.6645\n",
            "Epoch 27/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - Top2: 0.9235 - accuracy: 0.8151 - loss: 0.5535 - val_Top2: 0.9067 - val_accuracy: 0.7968 - val_loss: 0.6478\n",
            "Epoch 28/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - Top2: 0.9277 - accuracy: 0.8139 - loss: 0.5487 - val_Top2: 0.8761 - val_accuracy: 0.7551 - val_loss: 0.8113\n",
            "Epoch 29/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - Top2: 0.9256 - accuracy: 0.8226 - loss: 0.5383 - val_Top2: 0.9129 - val_accuracy: 0.8044 - val_loss: 0.6015\n",
            "Epoch 30/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 146ms/step - Top2: 0.9277 - accuracy: 0.8267 - loss: 0.5230 - val_Top2: 0.9148 - val_accuracy: 0.7970 - val_loss: 0.6307\n",
            "Epoch 31/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 148ms/step - Top2: 0.9290 - accuracy: 0.8234 - loss: 0.5316 - val_Top2: 0.9004 - val_accuracy: 0.7860 - val_loss: 0.6644\n",
            "Epoch 32/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - Top2: 0.9343 - accuracy: 0.8340 - loss: 0.4980 - val_Top2: 0.9060 - val_accuracy: 0.7965 - val_loss: 0.6343\n",
            "Epoch 33/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 146ms/step - Top2: 0.9337 - accuracy: 0.8347 - loss: 0.4954 - val_Top2: 0.9084 - val_accuracy: 0.7975 - val_loss: 0.6207\n",
            "Epoch 34/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - Top2: 0.9391 - accuracy: 0.8379 - loss: 0.4788 - val_Top2: 0.9039 - val_accuracy: 0.7925 - val_loss: 0.6382\n",
            "Epoch 1/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 88ms/step - Top2: 0.4406 - accuracy: 0.2443 - loss: 2.1938 - val_Top2: 0.2024 - val_accuracy: 0.0978 - val_loss: 3.6509\n",
            "Epoch 2/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - Top2: 0.6265 - accuracy: 0.3968 - loss: 1.6457 - val_Top2: 0.6124 - val_accuracy: 0.3988 - val_loss: 1.6574\n",
            "Epoch 3/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - Top2: 0.6972 - accuracy: 0.4711 - loss: 1.4706 - val_Top2: 0.6887 - val_accuracy: 0.4925 - val_loss: 1.4348\n",
            "Epoch 4/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - Top2: 0.7432 - accuracy: 0.5266 - loss: 1.3137 - val_Top2: 0.7552 - val_accuracy: 0.5359 - val_loss: 1.2961\n",
            "Epoch 5/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - Top2: 0.7649 - accuracy: 0.5596 - loss: 1.2393 - val_Top2: 0.7534 - val_accuracy: 0.5456 - val_loss: 1.2697\n",
            "Epoch 6/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - Top2: 0.7883 - accuracy: 0.5937 - loss: 1.1568 - val_Top2: 0.7880 - val_accuracy: 0.5931 - val_loss: 1.1411\n",
            "Epoch 7/100\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 90ms/step - Top2: 0.7993 - accuracy: 0.6057 - loss: 1.1086 - val_Top2: 0.7947 - val_accuracy: 0.6046 - val_loss: 1.1555\n",
            "Epoch 8/100\n",
            "\u001b[1m 17/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 83ms/step - Top2: 0.7984 - accuracy: 0.6162 - loss: 1.0947"
          ]
        }
      ],
      "source": [
        "best_f, best_d = DE(4, 4, func, func_limits)\n",
        "best_f, best_d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rt8S0wk2X7n6",
      "metadata": {
        "id": "Rt8S0wk2X7n6"
      },
      "outputs": [],
      "source": [
        "best_f, best_d"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def func(X):\n",
        "    amount_of_layer_1 =\n",
        "    amount_of_layer_2 =\n",
        "    amount_of_layer_3 =\n",
        "    amount_of_one_dence =\n",
        "    amount_of_one_filters = int(round(X[0]))\n",
        "    Dropout = X[1]\n",
        "    model_layers = [\n",
        "        layers.Input(shape=(32, 32, 3)),\n",
        "        data_augmentation\n",
        "    ]\n",
        "\n",
        "    for _ in range(amount_of_layer_1):\n",
        "        model_layers.append(layers.Conv2D(amount_of_one_filters, (3, 3), activation='relu', padding='same'))\n",
        "        model_layers.append(layers.BatchNormalization())\n",
        "    model_layers.append(layers.MaxPooling2D(2, 2))\n",
        "\n",
        "    for _ in range(amount_of_layer_2):\n",
        "        model_layers.append(layers.Conv2D(amount_of_one_filters * 2, (3, 3), activation='relu', padding='same'))\n",
        "        model_layers.append(layers.BatchNormalization())\n",
        "    model_layers.append(layers.MaxPooling2D(2, 2))\n",
        "    model_layers.append(layers.Dropout(0.3))\n",
        "\n",
        "    for _ in range(amount_of_layer_3):\n",
        "        model_layers.append(layers.Conv2D(amount_of_one_filters * 4, (3, 3), activation='relu', padding='same'))\n",
        "        model_layers.append(layers.BatchNormalization())\n",
        "    model_layers.append(layers.MaxPooling2D(4, 4))\n",
        "    model_layers.append(layers.Dropout(0.4))\n",
        "\n",
        "    model_layers.append(layers.Flatten())\n",
        "    for _ in range(amount_of_one_dence):\n",
        "        model_layers.append(layers.Dense(amount_of_one_filters * 8, activation='relu'))\n",
        "    model_layers.append(layers.Dropout(Dropout))\n",
        "    model_layers.append(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model = tf.keras.models.Sequential(model_layers)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=2, name=\"Top2\")])\n",
        "    history = model.fit(x_train, y_train, batch_size=128, epochs=100, validation_data=(x_val, y_val), callbacks=callbacks)\n",
        "    index = np.argmax(history.history['val_loss'])\n",
        "    return (1.0 - history.history['val_accuracy'][index]) + history.history['val_loss'][index]\n",
        "\n",
        "func_limits = [[16, 128], [0.01, 0.99]]"
      ],
      "metadata": {
        "id": "gxwXImxKogIv"
      },
      "id": "gxwXImxKogIv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dots = 8\n",
        "x1_lim = func_limits[0]\n",
        "x1 = np.linspace(x1_lim[0], x1_lim[1], dots)\n",
        "x2_lim = func_limits[1]\n",
        "x2 = np.linspace(x2_lim[0], x2_lim[1], dots)\n",
        "space = np.meshgrid(x1, x2)\n",
        "fitness = np.array([[func(np.array([i, j]))] for j in x2] for i in x1)"
      ],
      "metadata": {
        "id": "szCSiG2zqWvo"
      },
      "id": "szCSiG2zqWvo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "435a1640",
      "metadata": {
        "id": "435a1640"
      },
      "outputs": [],
      "source": [
        "# model = tf.keras.models.Sequential(\n",
        "#     [\n",
        "#         layers.Input(shape=(32, 32, 3)),\n",
        "\n",
        "#         data_augmentation,\n",
        "\n",
        "#         layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "#         layers.BatchNormalization(),\n",
        "#         layers.MaxPooling2D(2, 2),\n",
        "\n",
        "#         layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "#         layers.BatchNormalization(),\n",
        "#         layers.MaxPooling2D(2, 2),\n",
        "#         layers.Dropout(0.3),\n",
        "\n",
        "#         layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "#         layers.BatchNormalization(),\n",
        "#         layers.MaxPooling2D(4, 4),\n",
        "#         layers.Dropout(0.4),\n",
        "\n",
        "#         layers.Flatten(),\n",
        "#         layers.Dense(1024, activation='relu'),\n",
        "#         layers.Dropout(0.5),\n",
        "#         layers.Dense(y_test.shape[1], activation='softmax')\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# model.summary()\n",
        "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "#               loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "#               metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=2, name=\"Top2\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f83acd0",
      "metadata": {
        "id": "4f83acd0"
      },
      "outputs": [],
      "source": [
        "# history = model.fit(x_train, y_train, batch_size=128, epochs=100, validation_data=(x_val, y_val), callbacks=callbacks)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}